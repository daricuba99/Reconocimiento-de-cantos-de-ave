{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwhsxD6rJYYJ"
      },
      "source": [
        "# 1. Importar Frameworks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9zaqq8WJYY1"
      },
      "source": [
        "## Instalación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpDR7RGQJYY2"
      },
      "outputs": [],
      "source": [
        "!pip install matplotlib\n",
        "!pip install tensorflow_io==0.23.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxUJFW78JYY5"
      },
      "source": [
        "## Cargar Frameworks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzCh3kumJYY5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_io as tfio"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cargar archivos de Drive"
      ],
      "metadata": {
        "id": "LbLLBaadS4CY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wY1x-ZiE2Dxa"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRyoYQO1JYZJ"
      },
      "source": [
        "# 2. Cear Dataset de Tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sk9GipE-K-Lb"
      },
      "source": [
        "## Cargar audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvZUAupcJYZA"
      },
      "outputs": [],
      "source": [
        "def load_wav_16k_mono(filename):\n",
        "    # Load encoded wav file\n",
        "    file_contents = tf.io.read_file(filename)\n",
        "    # Decode wav (tensors by channels) \n",
        "    wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)\n",
        "    # Removes trailing axis\n",
        "    wav = tf.squeeze(wav, axis=-1)\n",
        "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
        "    # Goes from 44100Hz to 16000hz - amplitude of the audio signal\n",
        "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
        "    return wav"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPQxoUpNJYZJ"
      },
      "source": [
        "## Definir ruta negativa y positiva"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_MpVjYzJYZK"
      },
      "outputs": [],
      "source": [
        "POS = os.path.join('/content/drive/MyDrive/DLBirds/ZorzalComun')\n",
        "NEG = os.path.join('/content/drive/MyDrive/DLBirds/Ruido')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIzP5EGRJYZL"
      },
      "outputs": [],
      "source": [
        "pos = tf.data.Dataset.list_files(POS+'/*.wav')\n",
        "neg = tf.data.Dataset.list_files(NEG+'/*.wav')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEdQ07HVJYZL"
      },
      "source": [
        "## Combinar negativos y positivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZmV-GKKJYZM"
      },
      "outputs": [],
      "source": [
        "positives = tf.data.Dataset.zip((pos, tf.data.Dataset.from_tensor_slices(tf.ones(len(pos)))))\n",
        "negatives = tf.data.Dataset.zip((neg, tf.data.Dataset.from_tensor_slices(tf.zeros(len(neg)))))\n",
        "data = positives.concatenate(negatives)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzSRm_i9JYZN"
      },
      "source": [
        "# 3. Deternminar longitud media de los audios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tN8zDrGJYZO"
      },
      "outputs": [],
      "source": [
        "lengths = []\n",
        "for file in os.listdir(os.path.join('/content/drive/MyDrive/DLBirds/Coturnix')):\n",
        "    tensor_wave = load_wav_16k_mono(os.path.join('/content/drive/MyDrive/DLBirds/Coturnix', file))\n",
        "    lengths.append(len(tensor_wave))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6Zt1SjGJYZY"
      },
      "source": [
        "# 4. Construir espectograma."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_3On8LVJYZZ"
      },
      "source": [
        "## Función de preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_-pB57NJYZZ"
      },
      "outputs": [],
      "source": [
        "def preprocess(file_path, label): \n",
        "    wav = load_wav_16k_mono(file_path)\n",
        "    wav = wav[:48000]\n",
        "    zero_padding = tf.zeros([48000] - tf.shape(wav), dtype=tf.float32)\n",
        "    wav = tf.concat([zero_padding, wav],0)\n",
        "    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)\n",
        "    spectrogram = tf.abs(spectrogram)\n",
        "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
        "    return spectrogram, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnvRumXKJYZa"
      },
      "outputs": [],
      "source": [
        "filepath, label = positives.shuffle(buffer_size=10000).as_numpy_iterator().next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vR-8_EkdJYZb"
      },
      "outputs": [],
      "source": [
        "spectrogram, label = preprocess(filepath, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaTxT7RsJYZb"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(30,20))\n",
        "plt.imshow(tf.transpose(spectrogram)[0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdQ44lILJYZb"
      },
      "source": [
        "# 5. Crear particiones de entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thNmZcN4JYZg"
      },
      "source": [
        "## Create a Tensorflow Data Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnoYZhkQJYZg"
      },
      "outputs": [],
      "source": [
        "data = data.map(preprocess)\n",
        "data = data.cache()\n",
        "data = data.shuffle(buffer_size=1000)\n",
        "data = data.batch(16)\n",
        "data = data.prefetch(8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fk-HzuXJYZh"
      },
      "source": [
        "## Dividir en particiones de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLBiw_F4senj"
      },
      "outputs": [],
      "source": [
        "len(data)*.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JQu_U9LJYZo"
      },
      "outputs": [],
      "source": [
        "#El resultado obtenido en la línea anterior se introduce en data.take y data.skip\n",
        "train = data.take(31)\n",
        "test = data.skip(31).take(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1y6mu8WpJYZo"
      },
      "source": [
        "## Entrenando un Batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9GrbJn4AJYZo"
      },
      "outputs": [],
      "source": [
        "samples, labels = train.as_numpy_iterator().next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "j4VAEkXtJYZp"
      },
      "outputs": [],
      "source": [
        "samples.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGoQSZGJJYZp"
      },
      "source": [
        "# 6. Construir modelo Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5vgayYUJYZp"
      },
      "source": [
        "## Cargar frameworks de Tensorfflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "K28Q3cIpJYZq"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ux6lzNv3JYZq"
      },
      "source": [
        "## Modelo secuencial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "40reaUWjJYZq"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(16, (3,3), activation='relu', input_shape=(1491, 257,1)))\n",
        "model.add(Conv2D(16, (3,3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ixj_Qaz0JYZr"
      },
      "outputs": [],
      "source": [
        "model.compile('Adam', loss='BinaryCrossentropy', metrics=[tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "y9L0knFXJYZr"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oagQHRO4JYZs"
      },
      "source": [
        "## Entrenar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xE94wtdPJYZs"
      },
      "outputs": [],
      "source": [
        "hist = model.fit(train, epochs=5, validation_data=test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EwLjfHnMJYZs"
      },
      "outputs": [],
      "source": [
        "plt.title('Pérdidas')\n",
        "plt.plot(hist.history['loss'], 'r')\n",
        "plt.plot(hist.history['val_loss'], 'b')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4OUPxVUhJYZt"
      },
      "outputs": [],
      "source": [
        "plt.title('Precisión')\n",
        "plt.plot(hist.history['precision'], 'r')\n",
        "plt.plot(hist.history['val_precision'], 'b')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xckyqJOJYZt"
      },
      "outputs": [],
      "source": [
        "plt.title('Recall')\n",
        "plt.plot(hist.history['recall'], 'r')\n",
        "plt.plot(hist.history['val_recall'], 'b')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mqpk7bZLJYZx"
      },
      "source": [
        "# 7. Validación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPDAF7QlJYZ1"
      },
      "source": [
        "## Cargar archivos MP3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnFFM3XoJYZ2"
      },
      "outputs": [],
      "source": [
        "def load_mp3_16k_mono(filename):\n",
        "    \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
        "    res = tfio.audio.AudioIOTensor(filename)\n",
        "    # Convert to tensor and combine channels \n",
        "    tensor = res.to_tensor()\n",
        "    tensor = tf.math.reduce_sum(tensor, axis=1) / 2 \n",
        "    # Extract sample rate and cast\n",
        "    sample_rate = res.rate\n",
        "    sample_rate = tf.cast(sample_rate, dtype = tf.int64)\n",
        "    wav = tf.cast(sample_rate, dtype=tf.int64)\n",
        "    # Resample to 16 kHz\n",
        "    wav = tfio.audio.resample(tensor, sample_rate, 16000)\n",
        "    return wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wc4VhiZYJYZ2"
      },
      "outputs": [],
      "source": [
        "mp3 = os.path.join('/content/drive/MyDrive/DLBirds/ZorzalTest/XC112569 - Codorniz común - Coturnix coturnix.mp3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AetJ9wJTJYZ3"
      },
      "outputs": [],
      "source": [
        "wav = load_mp3_16k_mono(mp3)\n",
        "wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgLiA3jbJYZ3"
      },
      "outputs": [],
      "source": [
        "audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=48000, sequence_stride=48000, batch_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLJF5HY7JYZ3"
      },
      "outputs": [],
      "source": [
        "samples, index = audio_slices.as_numpy_iterator().next()\n",
        "samples.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZCTm9UqUcVN"
      },
      "outputs": [],
      "source": [
        "len(audio_slices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exiO3yJcJYZ4"
      },
      "source": [
        "## Función para enventanar los espectogramas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAEM4SORJYZ4"
      },
      "outputs": [],
      "source": [
        "def preprocess_mp3(sample, index):\n",
        "    sample = sample[0]\n",
        "    zero_padding = tf.zeros([48000] - tf.shape(sample), dtype=tf.float32)\n",
        "    wav = tf.concat([zero_padding, sample],0)\n",
        "    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)\n",
        "    spectrogram = tf.abs(spectrogram)\n",
        "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
        "    return spectrogram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIWsYnNYJYZ4"
      },
      "source": [
        "## Convertir los audios en ventanas y realizar predicciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rjn2cEOOJYZ5"
      },
      "outputs": [],
      "source": [
        "audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=48000, sequence_stride=48000, batch_size=1)\n",
        "audio_slices = audio_slices.map(preprocess_mp3)\n",
        "audio_slices = audio_slices.batch(64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPFskkJjJYZ5"
      },
      "outputs": [],
      "source": [
        "yhat = model.predict(audio_slices)\n",
        "yhat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2g0ojYYxD9Zl"
      },
      "outputs": [],
      "source": [
        "yhat = [1 if prediction > 0.99 else 0 for prediction in yhat]\n",
        "yhat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "602lftRjJYZ7"
      },
      "source": [
        "#8. Realizar Predicciones en varios audios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUWyYKwuJYZ7"
      },
      "source": [
        "## Bucle para cargar y evaluar los audios de una carpeta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0dkjQUbJYZ7"
      },
      "outputs": [],
      "source": [
        "results = {}\n",
        "for file in os.listdir(os.path.join('/content/drive/MyDrive/DLBirds/ZorzalTest')):\n",
        "    FILEPATH = os.path.join('/content/drive/MyDrive/DLBirds/ZorzalTest', file)\n",
        "    \n",
        "    wav = load_mp3_16k_mono(FILEPATH)\n",
        "    audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=48000, sequence_stride=48000, batch_size=1)\n",
        "    audio_slices = audio_slices.map(preprocess_mp3)\n",
        "    audio_slices = audio_slices.batch(64)\n",
        "    \n",
        "    yhat = model.predict(audio_slices)\n",
        "    \n",
        "    results[file] = yhat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjgQgGAOJYZ9"
      },
      "source": [
        "## Convertir predicciones en clases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrzPElVqJYZ9",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "class_preds = {}\n",
        "for file, logits in results.items():\n",
        "    class_preds[file] = [1 if prediction > 0.9 else 0 for prediction in logits]\n",
        "    sum = np.sum(class_preds[file])\n",
        "    class_preds[file] = 1 if sum > 0 else 0\n",
        "\n",
        "class_preds"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "3fk-HzuXJYZh",
        "h5vgayYUJYZp",
        "ux6lzNv3JYZq",
        "vPDAF7QlJYZ1",
        "exiO3yJcJYZ4"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}